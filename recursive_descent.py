import sys

class recursive_descent:
	"""
		:param tokens:  list of tuples (token, lexeme)
		:param resWords: reservedWords class instance
	""" 
	def __init__( self, dicts ):
		# open file and store pointer to in_fp
		self.noParen = 0

		self.RESERVED_WORDS = dicts.getReservedWordsDict()
		self.TOKEN = dicts.getTokenDict()
		"""
			ERROR CODES:
			100	:	Reserved word conflict
		"""

	# this method is called when we want to start lexing and parsing
	def run( self, tokens ):
		self.tokens = tokens
		self.start()

	def start( self ):
		print "Enter start()"
		self.declaration()
		print "Exit start()"

	def declaration( self ):
		print "Enter declaration()"
		if self.tokens[ 0 ][ 0 ] == self.TOKEN[ 'IDENT' ]:
			self.type()
			self.id()
			if self.tokens[ 0 ][ 0 ] == self.TOKEN[ 'ASSIGN_OP' ]:
				self.dequeueTokens()
				self.expr()
				if self.tokens[ 0 ][ 0 ] == self.TOKEN[ 'SEMICOLON' ]:
					self.dequeueTokens()
				else:
					self.error( 200 )
			else:
				self.error()
		print "Exit declaration()"

	def type( self ):
		print "Enter type()"
		safe = self.RESERVED_WORDS.get( self.tokens[ 0 ][ 1 ] )
		if safe is None :
			self.error( 100 )
		else:
			self.dequeueTokens()
		print "Exit type()"

	def expr( self ):#E->TE'
		print "Enter expr()"
		self.term()#parse the first term
		self.exprP()
		print "Exit expr()"
	def exprP( self ):# E'->{(+|-)TE'}
		print "Enter exprP()"
		if self.tokens[ 0 ][ 0 ] == self.TOKEN[ 'ADD_OP' ] or self.tokens[ 0 ][ 0 ] == self.TOKEN[ 'SUB_OP' ]:
			self.dequeueTokens()
			self.term()
			self.exprP()
		print "Exit exprP()"
	def term( self ):# T->FT'
		print "Enter term()"
		self.factor()#parse the first factor
		self.termP()
		print "Exit term()"
	def termP( self ):# T'->{(*|\)FT'}
		print "Enter termP()"
		if self.tokens[ 0 ][ 0 ] == self.TOKEN[ 'MULT_OP' ] or self.tokens[ 0 ][ 0 ] == self.TOKEN[ 'DIV_OP' ]:#as long as * or / comes next
			self.dequeueTokens()
			self.factor()
		print "Exit termP()"
	def factor( self ):# F->(E)|id
		print "Enter factor()"
		#self.dequeueTokens()
		if self.tokens[ 0 ][ 0 ]==self.TOKEN[ 'IDENT' ] or self.tokens[ 0 ][ 0 ]==self.TOKEN[ 'INT_LIT' ]:
			#self.dequeueTokens()#get token 
			self.id()

		else: #(<expr>)
			if self.tokens[ 0 ][ 0 ]==self.TOKEN[ 'LEFT_PAREN' ]:
				self.dequeueTokens()
				self.expr()
				if self.tokens[ 0 ][ 0 ]==self.TOKEN[ 'RIGHT_PAREN ']:
					self.dequeueTokens()
				else:
					self.error()
			else: #It was not an id, an integer literal, or a left parenthesis
				self.error()
		print "Exit factor()"

	def id( self ):# id->(a|b|c)
		print "Enter id()"
		self.dequeueTokens()
		print "Exit id()"

	def error( self, errorCode = 0 ):
		if errorCode == 0:
			tokens=['+','-','/','*','a','b','c','(',')','=']
			if tokens.count("".join(self.tokens[ 0 ][ 1 ]))>0:#error caused by lexeme read at a rule
				print "Syntax Error"
			else:
				print "Lexical Error in input. Lexeme","".join(self.lexeme),"is not in the grammar. Input is not generated by the grammar."
		elif errorCode == 1:
			print "ERROR CODE 1: Unexpected end-of-file."
		elif errorCode == 100:
			print "ERROR CODE 100: Identifier expected. Reserved word gotten."
		elif errorCode == 200:
			print "ERROR CODE 200: Semicolon expected."
		sys.exit( "Exiting program." )

	def dequeueTokens( self ):
		if self.tokens[ 0 ][ 0 ] == -1:
			print "EOF"
		else:
			self.tokens.pop( 0 )
